---
title: "Autonomous Underwater Manipulation"
excerpt: "Challenges, Improvements, and Implementation"
last_modified_at: 2025-08-26
header:
  teaser: /assets/images/seminar/thumbnail.png
  
tags: 
  - Projects
  - Computer Vision
---

## Overview

In the summer of 2025, I was invited to give a talk at work, as part of our seminar series. I would be focusing on underwater manipulation. This dovetailed nicely with needing to prepare a similar talk for the Oceans 2025 conference in October so I said yes. I was happy to have been asked to present, but I was also pretty nervous. 

The seminar timeslots are about 45 minutes of technical content, followed by a Q&A. I need to pull together graphics, videos, results...a summary of what I had spent about two years working on. It became quite daunting and stressful but I was ultimately quite happy with how it turned out. The full presentation is embedded below and I'll also provide some of the content here in blog form.

<iframe width="1737" height="887" src="https://www.youtube.com/embed/UgEWKAFAT24" title="Autonomous Underwater Manipulation: Challenges, Improvements, and Implementation" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>

### Background and Motivation

This project was funded by ONR and supported by Tim Player's development of an underwater grasp synthesis network, work that was done at Oregon State University. 

<figure >
    <a><img src="/assets/images/seminar/background.jpg"></a>
</figure>

Our lab's goals were, are a high-level to improve our capabilities to test, research, and ultimately perform underwater autonomous manipulation.

We’ve defined a few goal tasks to help orient our research,.
  * Grab generic handled objects in unstructured scenes
  * Pull pins, attach carabiners.

I’ll be focusing on this first goal:
* Grabbing generic handled objects in unstructured scenes
  - “generic” here means that we want this to work on any class of objects - we don’t need geometry or shape/CAD known *a priori*
  - “handled” means that the objects are meant to be grabbed. Our research is NOT on improving the grasp itself, we use an interlocking quad jaw set up and we’re not focused on pathological or deformable objects
-   And “unstructured scenes” means we should be able to operate without knowing the scene collision objects beforehand, nor should we be restricted to only operating in free-space
* We have mostly been using a kettlebell for our generic object.

The **WHY** behind all of this is that manipulation by ROVs (remotely operated vehicles) is very hard.

Currently, deploying a ROV with a manipulator requires at least one pilot, and operating them is a skilled job that can consume valuable mission time. If we can improve the robustness of that operation, we can help
Reduce overall mission cost by reducing personnel requirements and increase deployment opportunities. 

Obviously this is much easier said than done, working in the underwater domain introduces challenging environmental factors like turbidity and currents which make autonomy difficult.

Underwater domain limits which sensors you can you use (no Lidar!) but also the quality of the data you get - lotta noise.

Robotics arms on floating platforms are very challenging from a controls perspective. You have a relatively large arm on a relatively small platform which means you get a tight coupling of the dynamics between the two - you reach forward and the robot pitches forward at the same time. Or you retract your arm and the robot pitches backwards and also conserves momentum, moving backwards at the same time.

Our high-level approach has been to introduce a pragmatic amount of automation - understanding that it’s an enormous project to fully automate expensive scientific missions but introducing ways to speed up operations by automating SOME portions of the process is still valuable.

### Building Test Capabilities

As our lab started working on this problem, we understood that we needed to improve our in-house testing capabilities. We have a test tank in the basement of the lab, it's approximately 2m across and 1.5m deep. We added a 4 degree-of-freedom gantry that sits on top of the tank and provides controllable motion to a head that sits underwater. We can attach sensors and actuators to that head and know the position of it in real-time with a high degree of accuracy.

<video width="800" height="450" controls loop autoplay muted>
    <source src="/assets/images/seminar/test_capabilities.webm" type="video/webm">
</video>

It's fully integrated with our software stack and controllable via ROS (Robotic Operating System).

### Manipulation Pipeline Overview

### Perception and Mapping
### Grasp Generation and Selection
### Motion Planing
### Conclusions and Future Work

### References